{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60268305",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.6' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/kevin/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#IMPORTS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from google.colab import files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMBINING FILES\n",
    "\n",
    "\n",
    "#Get number of input files\n",
    "num_files = int(input(\"Enter # of files: \"))\n",
    "\n",
    "xarrs = []\n",
    "for i in range(num_files):\n",
    "    path = input(f\"Path to CSV #{i + 1}: \")\n",
    "    base = os.path.basename(path)\n",
    "    name, ext = os.path.splitext(base)\n",
    "    \n",
    "    #\"500_0.0019\" → [\"500\", \"0.0019\"]\n",
    "    try:\n",
    "        wl_str, bs_str = name.split('_')\n",
    "        wavelength = float(wl_str)\n",
    "        beam_size  = float(bs_str)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Name must be in '<wavelength>_<beam_size>.csv' format\")\n",
    "    \n",
    "    df  = pd.read_csv(path, header=None)\n",
    "    arr = df.values.reshape((256, 512, 256))\n",
    "    \n",
    "    #Creating xarray\n",
    "    da = xr.DataArray(\n",
    "        arr,\n",
    "        dims=(\"x\", \"y\", \"z\"),\n",
    "        coords={\n",
    "            \"x\": np.arange(arr.shape[0]),\n",
    "            \"y\": np.arange(arr.shape[1]),\n",
    "            \"z\": np.arange(arr.shape[2]),\n",
    "        },\n",
    "        attrs={\"units\": \"mW/mm²\"}\n",
    "    ).expand_dims(wavelength=[wavelength]) \\\n",
    "     .assign_coords(beam_size=beam_size)\n",
    "    \n",
    "    xarrs.append(da)\n",
    "\n",
    "combined = xr.concat(xarrs, dim=\"wavelength\").sortby(\"wavelength\")\n",
    "\n",
    "print(combined)\n",
    "combined.to_netcdf(\"combined.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INTERPOLATION\n",
    "\n",
    "#Get user input for uinterpolation\n",
    "w0 = float(input(\"Interp start wavelength: \"))\n",
    "w1 = float(input(\"Interp end wavelength: \"))\n",
    "wNum = int(input(\"# of wavelength points: \"))\n",
    "\n",
    "b0 = float(input(\"Interp start beam_size: \"))\n",
    "b1 = float(input(\"Interp end beam_size: \"))\n",
    "bNum= int(input(\"# of beam_size points: \"))\n",
    "\n",
    "#Checking inputted wavelength/beam sizes are valid based on inputted files\n",
    "min_wl = float(combined.wavelength.min())\n",
    "max_wl = float(combined.wavelength.max())\n",
    "if w0 < min_wl or w1 > max_wl or w0 > w1:\n",
    "    raise ValueError(\"Invalid wavelength inputted, must between min-max of inputted .csv\")\n",
    "\n",
    "bs_vals = combined.coords['beam_size'].values\n",
    "min_bs = float(np.min(bs_vals))\n",
    "max_bs = float(np.max(bs_vals))\n",
    "if b0 < min_bs or b1 > max_bs or b0 > b1:\n",
    "    raise ValueError(\"Invalid beam size inputted, must between min-max of inputted .csv\")\n",
    "\n",
    "waveList = np.linspace(w0, w1, wNum) \n",
    "beamList = np.linspace(b0, b1, bNum)  \n",
    "\n",
    "#Interpolate and save as new file\n",
    "if (bNum == 1):\n",
    "    fluence_interp = combined.interp(wavelength= waveList, method = \"linear\")\n",
    "elif (wNum == 1):\n",
    "    fluence_interp = combined.interp(beam_size = beamList, method = \"linear\")\n",
    "else:\n",
    "    fluence_interp = combined.interp(wavelength = waveList, beam_size = beamList, method = \"linear\")\n",
    "\n",
    "#Final result\n",
    "print(fluence_interp)\n",
    "fluence_interp.to_netcdf(\"fluence_interp.nc\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
